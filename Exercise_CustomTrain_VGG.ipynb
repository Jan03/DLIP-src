{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise_CustomTrain_VGG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykkimhgu/DLIP-src/blob/main/Exercise_CustomTrain_VGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0yKMyUBeU3P"
      },
      "source": [
        "# **DLIP Exercise**\n",
        "# VGG-16  using Keras\n",
        "Y.-K. Kim\n",
        "(updated 2021. 5. 3) \n",
        "\n",
        "Also, refer to  https://keras.io/guides/sequential_model/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiyQVvCfiolg"
      },
      "source": [
        "# Exercise : Train VGG-16 with Custom Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40ydDviLSPsb"
      },
      "source": [
        "![vgg16.png](https://gblobscdn.gitbook.com/assets%2F-MR8tEAjhiC8uN1kHR2J%2Fsync%2Ffa86476c1cfc7bc38d4cf74f532c85acc763f226.png?alt=media)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5fya61jgJdH"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "print(keras.__version__)\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        "import numpy as np \n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ1vQcw8jFHd"
      },
      "source": [
        "## **Custom Data Preparation for Training**\n",
        "Then load the image with size 224x224\n",
        "\n",
        "The input data should be 4-D: samples, rows, columns, and channels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRmggMFRcFvN"
      },
      "source": [
        "### Download Data\n",
        "\n",
        " Cats vs Dogs images dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IQq2w_8cAHA"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "-O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsw5Yl8Xl92_"
      },
      "source": [
        "Unzip the dataset files in the same directory  `/tmp/`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbMGdEQrcL3X"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nq1bhEZmOWb"
      },
      "source": [
        "Save each directory as variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgzHcda6cQ0q"
      },
      "source": [
        "# Base DIR\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Train Data\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "print(train_cats_dir)\n",
        "print(train_dogs_dir)\n",
        "\n",
        "# Validation  Data\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "print(validation_cats_dir)\n",
        "print(validation_dogs_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB1MuZD5csM2"
      },
      "source": [
        "### View Train Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ7R3CE7naw6"
      },
      "source": [
        "train_cat_fnames = os.listdir( train_cats_dir )\n",
        "train_dog_fnames = os.listdir( train_dogs_dir )\n",
        "\n",
        "nrows, ncols = 4, 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*3, nrows*3)\n",
        "\n",
        "cats = [os.path.join(train_cats_dir, fname)\n",
        "        for fname in train_cat_fnames[0:8]]\n",
        "dogs = [os.path.join(train_dogs_dir, fname)\n",
        "        for fname in train_dog_fnames[0:8]]\n",
        "\n",
        "for i, img_path in enumerate(cats+dogs):\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off')\n",
        "\n",
        "  img = image.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr_ZSfu4o51m"
      },
      "source": [
        "## **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIHGElWzpMXE"
      },
      "source": [
        "Use image data generator to preprocess images.\n",
        "\n",
        "Generate batches of tensor image data with real-time data augmentation.\n",
        "\n",
        "\n",
        "https://keras.io/api/preprocessing/image/#imagedatagenerator-class\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NEDtu1AcwSG"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                  batch_size=20,\n",
        "                                                  class_mode='binary',\n",
        "                                                  target_size=(224, 224))\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                       batch_size=20,\n",
        "                                                       class_mode  = 'binary',\n",
        "                                                       target_size = (224, 224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl4Wb2SCpx1A"
      },
      "source": [
        "## **CNN Model Design**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sdg2HVmdp-uf"
      },
      "source": [
        "Build Model (VGG-16  or similar model)\n",
        "\n",
        "You need to change the CNN model for binary classification !!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJK2q1lai9bN"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "\n",
        "\n",
        "# load the model\n",
        "model = VGG16( weights=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9PefPXRqTMt"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhxqPBFXqqUn"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlY-BCOjqOHm"
      },
      "source": [
        "## **Train Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrRo6gKhqAXp"
      },
      "source": [
        "Train model\n",
        "\n",
        "\n",
        "`history=modle.fit(    )`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mthXoQxQtB9n"
      },
      "source": [
        "history = model.fit(train_generator,\n",
        "                    validation_data=validation_generator,                    \n",
        "                    epochs=50,                    \n",
        "                    verbose=2)          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWT4YW7mJGLh"
      },
      "source": [
        "## **Test the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQJ1QD50tUU8"
      },
      "source": [
        "Print loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GpKQeUiJJa_"
      },
      "source": [
        "#YOUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUfhC-URlsGH"
      },
      "source": [
        "## **Evaluate the trained model**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFitD-Wu8mgl"
      },
      "source": [
        "Plot some test images and inference results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kLbbOjl78Kt"
      },
      "source": [
        "#YOUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdtTh3hF57OS"
      },
      "source": [
        "### Plot Learning Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr4BFZBG59vd"
      },
      "source": [
        "\n",
        "#YOUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}