{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial_VGG_Keras 2021",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1tdWUk8vHUNHEiuHHaxZ7qp-TEA49ja3D",
      "authorship_tag": "ABX9TyPklwbAoLlSITYVUBsHLxbd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykkimhgu/DLIP-src/blob/main/Tutorial_VGG_Keras_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0yKMyUBeU3P"
      },
      "source": [
        "# **DLIP Exercise**\n",
        "# VGG-16  using Keras\n",
        "Y.-K. Kim\n",
        "(updated 2021. 5. 3) \n",
        "\n",
        "Also, refer to  https://keras.io/guides/sequential_model/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYIplf96SPsB"
      },
      "source": [
        "# Exercise\n",
        "1. Build VGG-16\n",
        "2. Build VGG-19\n",
        "3. Use VGG-16 pretrained weights to classify objects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lHqSoDaeUSs"
      },
      "source": [
        "---\n",
        "## Import Keras and Numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5fya61jgJdH"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "print(keras.__version__)\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        "import numpy as np \n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrbAicLhSPsb"
      },
      "source": [
        "## Exercise 1: Build CNN model: VGG-16\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40ydDviLSPsb"
      },
      "source": [
        "![vgg16.png](https://gblobscdn.gitbook.com/assets%2F-MR8tEAjhiC8uN1kHR2J%2Fsync%2Ffa86476c1cfc7bc38d4cf74f532c85acc763f226.png?alt=media)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMBOMMKsSPsc"
      },
      "source": [
        "![vgg16.png](https://gblobscdn.gitbook.com/assets%2F-MR8tEAjhiC8uN1kHR2J%2Fsync%2F5a61fc6b487081994603219232fe9538d1d81375.png?alt=media)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5r-oMTEWMRw"
      },
      "source": [
        "# ADD YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r23pr08gSPsd"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCIHYpabWWS0"
      },
      "source": [
        "## Exercise 2: Build CNN model: VGG-19\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fL_qRmUYBuz"
      },
      "source": [
        "![vgg19.png](https://gblobscdn.gitbook.com/assets%2F-MR8tEAjhiC8uN1kHR2J%2Fsync%2F49091783c7f2589116be286cb247d4ed62df72ee.png?alt=media)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZp3UFySYRl_"
      },
      "source": [
        "# ADD YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQxgyibRYRl_"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps5n3T_UWewv"
      },
      "source": [
        "## Exercise 3: Use Pretrained VGG to classify objects\n",
        "\n",
        "Load images and classify using pretrained VGG-16 (Imagenet)\n",
        "\n",
        "Read here for instructions\n",
        "\n",
        "https://keras.io/api/applications/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0j9rCAfaC3v"
      },
      "source": [
        "### Load VGG Model\n",
        "\n",
        "Check this model with the one you have created above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7_ZvFs6as4-"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "\n",
        "\n",
        "# load the model\n",
        "model = VGG16( weights=\"imagenet\")\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpR7XmTdcYFu"
      },
      "source": [
        "### Data Preparation\n",
        "Then load the image with size 224x224\n",
        "\n",
        "The input data should be 4-D: samples, rows, columns, and channels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5IUNTfZck_1"
      },
      "source": [
        "img_path ='1.jpg'\n",
        "# load an image from file\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "\n",
        "# Convert the image pixels to a numpy array\n",
        "img = image.img_to_array(img)\n",
        "\n",
        "# Convert the images as (#sample, row, cols, Ch) \n",
        "img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
        "print(img.shape)\n",
        "\n",
        "# prepare the image for the VGG model\n",
        "x = preprocess_input(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8AX1Reta9HE"
      },
      "source": [
        "### Predict (Classify ) an image\n",
        "\n",
        "Upload given images in the colab directory. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBD-8E-ta8jF"
      },
      "source": [
        "preds = model.predict(x)\n",
        "# decode the results into a list of tuples (class, description, probability)\n",
        "# (one such list for each sample in the batch)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v39bd1fff1u1"
      },
      "source": [
        "convert the probabilities to class labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdr0KDfEf07q"
      },
      "source": [
        "# convert the probabilities to class labels\n",
        "label = decode_predictions(preds, top=3)\n",
        "\n",
        "# print the classification\n",
        "label_0=label[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoSgRirAg158"
      },
      "source": [
        "Print the predicted classification  with likelihood."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqx2X6mRgg1B"
      },
      "source": [
        "# print the classification\n",
        "#  ClassName - ClassDescription-Score\n",
        "print('%s (%.2f%%)' % (label_0[1], label_0[2]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_9NYIS2hpDX"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "1. Load other images and check for results\n",
        "\n",
        "2. Stream you webcam camera and classify captured image\n",
        "\n",
        "\n",
        "* Click snippet panel\n",
        "* Click Camera Capture. Click insert\n",
        "* Run scrip\n",
        "* Capture Image"
      ]
    }
  ]
}